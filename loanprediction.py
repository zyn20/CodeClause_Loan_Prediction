# -*- coding: utf-8 -*-
"""LoanPrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T0fSMNsYeIiQVpvQFg-wOHbphZbcYNyc
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

dataset = pd.read_csv('Loan_train.csv')

dataset.head()

#Now finding the Shape of data means numbers of Rows and Columns (rows,col)
dataset.shape

#check the missing values and datatypes
dataset.info()

dataset.describe()

pd.crosstab(dataset['Credit_History'],dataset['Loan_Status'],margins=True)

"""#We can cearly see that a person with credit history False have more chances of rejection as compared to credit history True"""

dataset.boxplot(column='ApplicantIncome')

"""#As we can see that there are too manu outliers so we are gonna remove these outliers """

dataset['ApplicantIncome'].hist(bins=20)
#X axis representing the Income of the Applicant and Y axis is representing its Frequency

dataset['CoapplicantIncome'].hist(bins=20)
#X axis representing the Income of the Applicant and Y axis is representing its Frequency

#comparing Loan status on the basis of appicant income vs Education
dataset.boxplot(column='ApplicantIncome' , by='Education')

#comparing Loan status on the basis of appicant income vs Self eMployed
dataset.boxplot(column='ApplicantIncome' , by='Self_Employed')

#Here we have Same situation as we have outliers
dataset.boxplot(column='LoanAmount')

"""#Taking the Histogram of LoanAmount Variable"""

dataset['LoanAmount'].hist(bins=20)

"""#Data is little right Skewed"""

#Normalizing the data

dataset['LoanAmount_log'] = np.log(dataset['LoanAmount'])

dataset['LoanAmount_log'].hist(bins=20)

"""the np.log() function is applied to the 'LoanAmount' column, and the resulting logarithmic values are assigned to a new column called 'LoanAmount_log' in the 'dataset' DataFrame.
#Now data is pretty normal
"""

dataset.isnull()

dataset.isnull().sum()

#Now we are going to fill the null values by mean or median or mode
#Firstly Filling the Gender by taking the mode as Gender belongs to Qualitative data
dataset['Gender'].fillna(dataset['Gender'].mode()[0],inplace=True)

dataset['Gender']

dataset['Gender'].isnull()

dataset.isnull().sum()

dataset['Married'].fillna(dataset['Gender'].mode()[0],inplace=True)

dataset['Dependents'].hist(bins=20)

dataset.describe()

dataset['Dependents'].fillna(dataset['Dependents'].mode()[0], inplace=True)

dataset['Self_Employed'].fillna(dataset['Self_Employed'].mode()[0], inplace=True)

dataset['LoanAmount'].fillna(dataset['LoanAmount'].mean(), inplace=True)

dataset['LoanAmount_log'].fillna(dataset['LoanAmount_log'].mean(), inplace=True)

dataset.isnull().sum()

dataset['Loan_Amount_Term'].fillna(dataset['Loan_Amount_Term'].mean(), inplace=True)

dataset['Credit_History'].fillna(dataset['Credit_History'].mean(), inplace=True)

dataset.isnull().sum()



"""We have Filled the Null Values Now"""

dataset['ApplicantIncome'].hist(bins=20)

"""Data is Skew-symmetric"""

dataset['CoapplicantIncome'].hist(bins=20)

"""Data is Skew Symmetric"""

#Total income = Applicant Income plus CoapplicantIncome
dataset['Total_Income'] = dataset['ApplicantIncome'] + dataset['CoapplicantIncome']

dataset['Total_Income'].hist(bins=20)

#Now Normalizing the data
dataset['Total_Income_log'] = np.log(dataset['Total_Income'])

dataset['Total_Income_log'].hist(bins=20)

"""Total Income is Normalized Now

"""

dataset.head()

#Now dividing the data into dependent and independent variables
dataset.shape

#. The .iloc attribute is used to perform integer-based indexing and slicing.
#If you prefer to use label-based indexing (using column names), you can use the .loc attribute instead.
X = dataset.iloc[:,np.r_[1:5,9:11,13:15]].values
#Columns 0,1,2,3,8,9,12,13

Y = dataset.iloc[:,12].values

Y

#Now splitting data into train and test